{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/sandeep_cse/Topic-Based-Image-Captioning')\n",
    "\n",
    "from dataset.utils import load_image\n",
    "from models.utils import load_pre_trained_image_model\n",
    "from evaluation.predictions import generate_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\" Load word index dictionary \"\"\"\n",
    "    word_idx_cache_path = os.path.join(\n",
    "        data_dir, 'word_idx.pkl'\n",
    "    )\n",
    "    idx_word_cache_path = os.path.join(\n",
    "        data_dir, 'idx_word.pkl'\n",
    "    )\n",
    "\n",
    "    word_idx_path_exists = os.path.exists(word_idx_cache_path)\n",
    "    idx_word_path_exists = os.path.exists(idx_word_cache_path)\n",
    "    if idx_word_path_exists and word_idx_path_exists:\n",
    "        with open(word_idx_cache_path, mode='rb') as file:\n",
    "            word_idx = pickle.load(file)\n",
    "        with open(idx_word_cache_path, mode='rb') as file:\n",
    "            idx_word = pickle.load(file)\n",
    "        print(\"Dictionary loaded.\")\n",
    "    else:\n",
    "        sys.exit('File containing the dictionary does not exist.')\n",
    "\n",
    "    return word_idx, idx_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load dictionaries\n",
    "word_idx, idx_word = load_data(\n",
    "    '/home/sandeep_cse/Topic-Based-Image-Captioning/dataset/processed_data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sandeep_cse/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/sandeep_cse/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/sandeep_cse/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Load caption model\n",
    "caption_model = load_model(\n",
    "    '/home/sandeep_cse/Topic-Based-Image-Captioning/weights/caption_model.hdf5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_input(topic_model_path, img_path):\n",
    "    # Load pre-trained image models\n",
    "    topic_model, feature_model = load_pre_trained_image_model(topic_model_path)\n",
    "\n",
    "    # Load image batch\n",
    "    image_batch = process_image(\n",
    "        img_path, K.int_shape(feature_model.input)[1:3]\n",
    "    )\n",
    "\n",
    "    # Create input data\n",
    "    feature_values = feature_model.predict(image_batch)\n",
    "    topic_values = topic_model.predict(feature_values)\n",
    "\n",
    "    return topic_values[0], feature_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path, img_size):\n",
    "    # Convert image to vector\n",
    "    img = load_image(img_path, size=img_size, grayscale=False)\n",
    "\n",
    "    # Create image batch\n",
    "    shape = (1,) + img_size + (3,)\n",
    "    image_batch = np.zeros(shape=shape, dtype=np.float32)\n",
    "    image_batch[0] = img\n",
    "\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained image models...\n",
      "WARNING:tensorflow:From /home/sandeep_cse/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_values, feature_values =  get_model_input(\n",
    "    '/home/sandeep_cse/Topic-Based-Image-Captioning/weights/topic_model.hdf5',\n",
    "    '/home/sandeep_cse/sat_imgs/11.jpg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = process_image('/home/sandeep_cse/sat_imgs/11.jpg', (299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input data\n",
    "feature_values = feature_model.predict(image_batch)\n",
    "topic_values = topic_model.predict(feature_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_caption = generate_predictions(\n",
    "    topic_values,\n",
    "    feature_values,\n",
    "    caption_model,\n",
    "    word_idx,\n",
    "    idx_word,\n",
    "    16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a woman standing in front of a fruit stand filled with fruit'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
