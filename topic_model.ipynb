{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.applications import VGG19\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the datset\n",
    "data_dir = 'dataset/processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, data_dir, data_type):\n",
    "    h5f = h5py.File(os.path.join(data_dir, filename), 'r')\n",
    "    data = h5f[data_type][:]\n",
    "    h5f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_data('train_images.h5', data_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories = load_data('train_categories.h5', data_dir, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = load_data('val_images.h5', data_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_categories = load_data('val_categories.h5', data_dir, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = load_data('test_images.h5', data_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categories = load_data('test_categories.h5', data_dir, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/coco_raw.pickle', 'rb') as file:\n",
    "    coco_raw = pickle.load(file)\n",
    "id_category = coco_raw['id_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(id_category)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_train = train_images.shape[0]\n",
    "num_images_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image\n",
    "idx = 10\n",
    "\n",
    "for category, value in enumerate(train_categories[idx]):\n",
    "    if value != 0:\n",
    "        print(id_category[category])\n",
    "\n",
    "plt.imshow(train_images[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download VGG19 model along with the fully-connected layers\n",
    "model = VGG19(include_top=True, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last layer from the last convolutional block\n",
    "conv_layer = model.get_layer('block5_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "conv_model = Model(inputs=model.input, outputs=conv_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new Keras Sequential model\n",
    "image_model = Sequential()\n",
    "\n",
    "# Add the convolutional part of the VGG19 model\n",
    "image_model.add(conv_model)\n",
    "\n",
    "# Flatten the output of the VGG19 model because it is from a\n",
    "# convolutional layer\n",
    "image_model.add(Flatten())\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "# This is for combining features that the VGG19 model has\n",
    "# recognized in the image.\n",
    "image_model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "# Add a dropout-layer which may prevent overfitting and\n",
    "# improve generalization ability to unseen data e.g. the test-set.\n",
    "# image_model.add(Dropout(0.5))\n",
    "\n",
    "# Add the final layer for the actual classification\n",
    "image_model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the VGG19 layers to be non-trainable\n",
    "conv_model.trainable = False\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "image_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = 'weights'\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.mkdir(weights_dir)\n",
    "\n",
    "path_checkpoint = os.path.join(weights_dir, 'checkpoint.keras')\n",
    "\n",
    "# set model callbacks\n",
    "tb = TensorBoard(log_dir=os.path.join(weights_dir, 'tensorboard-logs'), histogram_freq=0, write_graph=False)\n",
    "checkpoint = ModelCheckpoint(filepath=path_checkpoint, verbose=1, save_weights_only=True)\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "callbacks = [tb, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously trained model weights\n",
    "try:\n",
    "    image_model.load_weights(path_checkpoint)\n",
    "    print('Checkpoint loaded.')\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.fit(\n",
    "    x=train_images,\n",
    "    y=train_categories,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_images, val_categories)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(image, label, id_category):\n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "    predictions = image_model.predict(image_batch)\n",
    "    \n",
    "    prediction_labels = []\n",
    "    for index, prediction_probability in enumerate(predictions[0]):\n",
    "        if prediction_probability > 0.5:\n",
    "            prediction_labels.append(id_category[index])\n",
    "    \n",
    "    true_labels = []\n",
    "    for index, value in enumerate(label):\n",
    "        if value == 1:\n",
    "            true_labels.append(id_category[index])\n",
    "    \n",
    "    print('True labels:', true_labels)\n",
    "    print('Predictions:', prediction_labels)\n",
    "    \n",
    "    print('Image:')\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 18\n",
    "get_predictions(test_images[idx], test_categories[idx], id_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
