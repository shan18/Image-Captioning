{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset.utils import load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.applications import VGG19\n",
    "from tensorflow.python.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2) # To always load the same images in each dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the datset\n",
    "data_dir = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, data_dir):\n",
    "    images_path = os.path.join(data_dir, filename)\n",
    "    with open(images_path, 'rb') as file:\n",
    "        images = pickle.load(file)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train_images = load_data('train_images.pkl', data_dir)\n",
    "train_categories = load_data('train_categories.pkl', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation data\n",
    "val_images = load_data('val_images.pkl', data_dir)\n",
    "val_categories = load_data('val_categories.pkl', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_images = load_data('test_images.pkl', data_dir)\n",
    "test_categories = load_data('test_categories.pkl', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapping\n",
    "with open('dataset/coco_raw.pickle', 'rb') as file:\n",
    "    coco_raw = pickle.load(file)\n",
    "id_category = coco_raw['id_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_train = len(filenames_train)\n",
    "num_images_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to load and display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size=None, grayscale=False):\n",
    "    \"\"\"\n",
    "    Load the image from the given file-path and resize it\n",
    "    to the given size if not None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image using opencv\n",
    "    if not grayscale:  # BGR format\n",
    "        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    else:  # grayscale format\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Resize image if desired.\n",
    "    if not size is None:\n",
    "        image = cv2.resize(image, size)\n",
    "\n",
    "    # Convert image to numpy array and scale pixels so they fall between 0.0 and 1.0\n",
    "    image = np.array(image) / 255.0\n",
    "\n",
    "    # Add 1 extra dimension to grayscale images\n",
    "    if (len(image.shape) == 2):\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(idx, train):\n",
    "    \"\"\"\n",
    "    Load and plot an image from the training or validation set\n",
    "    with the given index.\n",
    "    \"\"\"\n",
    "\n",
    "    if train:\n",
    "        # Use an image from the training-set\n",
    "        filename = filenames_train[idx]\n",
    "        categories = categories_train[idx]\n",
    "    else:\n",
    "        # Use an image from the validation-set\n",
    "        filename = filenames_val[idx]\n",
    "        categories = categories_val[idx]\n",
    "\n",
    "    # Path for the image-file.\n",
    "    path = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Print the captions for this image.\n",
    "    for category in categories:\n",
    "        print(category)\n",
    "    \n",
    "    # Load the image and plot it.\n",
    "    img = load_image(path)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=1, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Image Model (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download VGG16 model along with the fully-connected layers\n",
    "model = VGG19(include_top=True, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the second last layer which is a fully-connected layer\n",
    "transfer_layer = model.get_layer('block5_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoder model\n",
    "conv_model = Model(inputs=model.input, outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new Keras Sequential model.\n",
    "image_model = Sequential()\n",
    "\n",
    "# Add the convolutional part of the VGG16 model from above.\n",
    "image_model.add(conv_model)\n",
    "\n",
    "# Flatten the output of the VGG16 model because it is from a\n",
    "# convolutional layer.\n",
    "image_model.add(Flatten())\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "# This is for combining features that the VGG16 model has\n",
    "# recognized in the image.\n",
    "image_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Add a dropout-layer which may prevent overfitting and\n",
    "# improve generalization ability to unseen data e.g. the test-set.\n",
    "image_model.add(Dropout(0.5))\n",
    "\n",
    "# Add the final layer for the actual classification.\n",
    "image_model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layer_trainable():\n",
    "    for layer in conv_model.layers:\n",
    "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer_trainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.trainable = False\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print_layer_trainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
